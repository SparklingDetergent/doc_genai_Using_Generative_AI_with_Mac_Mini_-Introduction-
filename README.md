# doc_genai_Using_Generative_AI_with_Mac_Mini_-Introduction-
Mac Miniでの生成AI活用（導入）

<br/><br/>
## 目次

- [はじめに](#はじめに)
- [生成AIの成り立ちや種類について](#生成aiの成り立ちや種類について)
  - [AIの種類](#aiの種類)
  - [生成AIの種類](#生成aiの種類)
  - [生成AIの活用事例](#生成aiの活用事例)
- [LLMの利用形態について](#llmの利用形態について)
  - [LLMの動作環境](#llmの動作環境)
  - [ローカルLLMを動作させる機器](#ローカルllmを動作させる機器)
  - [具体的なユースケース例](#具体的なユースケース例)
- [ローカルLLMの動作環境について](#ローカルllmの動作環境について)
  - [メモリ・演算装置](#メモリ・演算装置)
  - [アプリケーション](#アプリケーション)
  - [モデルサイズ](#モデルサイズ)
- [ローカルLLMの業務利用導入手順について](#ローカルllmの業務利用導入手順について)
  - [検証段階](#検証段階)
  - [運用段階](#運用段階)
  - [管理段階](#管理段階)
- [ローカルLLMの業務利用導入後の展望について](#ローカルllmの業務利用導入後の展望について)
  - [展望](#展望)
  - [まとめ](#まとめ)

<br/><br/>
## はじめに

- Mac Apple siliconにより構成されたMac Miniを用いてローカルLLMによるAIチャット機能を導入し、業務効率化を実現することを目指します。
- 下記図表の印「■」については、この目的に沿って着目するべきキーワードに記しています。
- 下記図表ではキーワードのみ記しているため、詳細をご覧になりたい場合は、各章のリンクをご参照ください。

https://github.com/SparklingDetergent/doc_genai_Using_Generative_AI_with_Mac_Mini_M1_-Server_Setup-

<br/><br/>
## 生成AIの成り立ちや種類について

### AIの種類

```mermaid
graph LR
    A[AIの種類] --> B[人間（対比として）]
    A --> C[従来のAI]
    A --> D[生成AI■]
```

<br/><br/>
### 生成AIの種類

```mermaid
graph LR
    A[生成AIの種類] --> B[画像生成]
    A --> C[テキスト生成・LLM■]
    A --> D[動画生成]
```

<br/><br/>
### 生成AIの活用事例

| 分野 | 活用例 |
|------|--------|
| マーケティング | 広告文言生成 |
| カスタマーサービス | チャットボット |
| 業務■ | レポート作成支援 |
| 教育 | 個別化学習コンテンツ |
| 医療 | 診断支援 |
| エンターテイメント | ゲームシナリオ生成 |

<br/><br/>
## LLMの利用形態について

### LLMの動作環境

```mermaid
graph LR
    A[LLMの動作環境] --> B[クラウドサービス上のLLM]
    A --> C[クラウド環境へデプロイするLLM]
    A --> D[ローカル環境で動作するLLM■]
```

**補足**: ローカル環境で動作するLLMについては、Hugging Face等のサイトで配布されているモデルを、ライセンスに応じて利用可能です。

<br/><br/>
### ローカルLLMを動作させる機器

```mermaid
graph LR
    A[動作機器] --> B[ワークステーション]
    A --> C[エッジサーバー■]
    A --> D[AI専用機器]
```

<br/><br/>
### 具体的なユースケース例

| ユースケース | 説明 |
|--------------|------|
| 社内情報検索システム | 社内文書の効率的な検索・要約 |
| 顧客対応チャットボット | 24時間対応の自動応答 |
| コーディング支援■ | プログラミング補助・デバッグ支援 |
| オフライン翻訳 | インターネット接続不要の翻訳 |
| 医療現場での診断支援 | 症状に基づく初期診断補助 |

<br/><br/>
## ローカルLLMの動作環境について

### メモリ・演算装置

| メモリ種類 | 演算装置 |
|------------|----------|
| RAM | CPU |
| VRAM | GPU |
| 共有メモリ■ | CPU, GPU, NPU |

<br/><br/>
### アプリケーション

```mermaid
graph LR
    A[アプリケーション] --> B[Transformers]
    A --> C[llama.cpp■]
    A --> D[MLX]
    A --> E[ONNX Runtime]
```

<br/><br/>
### モデルサイズ

```mermaid
graph LR
    A[モデルサイズ] --> B[1-3B]
    A --> C[3-9B]
    A --> D[9-27B■]
    A --> E[27B以上]
```

<br/><br/>
## ローカルLLMの業務利用導入手順について

### 検証段階

```mermaid
graph TD
    A[検証段階] --> B[検証期間]
    A --> C[ログ分析■]
    A --> D[業務成果との比較]
    A --> E[効果検証]
```

<br/><br/>
### 運用段階

```mermaid
graph TD
    A[運用段階] --> B[マニュアル化]
    A --> C[展開]
    A --> D[継続的な改善■]
```

<br/><br/>
### 管理段階

```mermaid
graph TD
    A[管理段階] --> B[新モデルと機器の評価]
    A --> C[スケーラビリティの検討]
    A --> D[評価体制の構築]
    A --> E[評価手順の整備■]
```

<br/><br/>
## ローカルLLMの業務利用導入後の展望について

### 展望

```mermaid
graph LR
    A[展望] --> B[マルチモーダル導入■]
    A --> C[RAG導入]
    A --> D[エージェント技術導入]
    A --> E[LLMアプリケーション導入]
```

<br/><br/>
### まとめ

ローカルLLMの導入により、セキュリティを確保しつつ、業務効率化を実現できます。継続的な評価と改善が重要です。
